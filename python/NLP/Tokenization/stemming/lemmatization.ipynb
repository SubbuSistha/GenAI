{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization: Definition & Working<br>\n",
    "Lemmatization is a text normalization technique in Natural Language Processing (NLP) that reduces words to their base or dictionary form (lemma) while considering the context and part of speech (POS). Unlike stemming, lemmatization ensures that the output is always a valid word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How Lemmatization Works Internally<br>\n",
    "POS Tagging:<br>\n",
    "\n",
    "Words are assigned their Part-of-Speech (e.g., noun, verb, adjective).\n",
    "Example:<br>\n",
    "\"running\" (verb) → lemma = \"run\"\n",
    "\"better\" (adjective) → lemma = \"good\"\n",
    "Morphological Analysis:\n",
    "\n",
    "The algorithm identifies prefixes, suffixes, and inflections to determine the base form.\n",
    "Example: \"studies\" (noun) → \"study\"\n",
    "Dictionary Lookup:\n",
    "\n",
    "The system checks a lexical database (like WordNet) to find the correct lemma.\n",
    "Example: \"went\" (past tense of \"go\") → \"go\" (correct lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"eating\",'fairly','fasting','having', 'running','history','historically','final','stemming','algorithms','however','removes']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\krith\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating-------->eating\n",
      "fairly-------->fairly\n",
      "fasting-------->fasting\n",
      "having-------->having\n",
      "running-------->running\n",
      "history-------->history\n",
      "historically-------->historically\n",
      "final-------->final\n",
      "stemming-------->stemming\n",
      "algorithms-------->algorithm\n",
      "however-------->however\n",
      "removes-------->remove\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "[print(f\"{word}-------->{lemmatizer.lemmatize(word)}\") for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating-------->eat\n",
      "fairly-------->fairly\n",
      "fasting-------->fast\n",
      "having-------->have\n",
      "running-------->run\n",
      "history-------->history\n",
      "historically-------->historically\n",
      "final-------->final\n",
      "stemming-------->stem\n",
      "algorithms-------->algorithms\n",
      "however-------->however\n",
      "removes-------->remove\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(f\"{word}-------->{lemmatizer.lemmatize(word,'v')}\") for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "better\n",
      "better\n",
      "good\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize('better'))\n",
    "print(lemmatizer.lemmatize('better','v'))\n",
    "print(lemmatizer.lemmatize('better','a'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
